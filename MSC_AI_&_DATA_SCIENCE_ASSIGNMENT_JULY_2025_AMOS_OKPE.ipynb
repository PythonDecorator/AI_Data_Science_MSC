{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3WTOQ1Z0SkHG8cSRdhVHk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PythonDecorator/AI_Data_Science_MSC/blob/Assignment-2025-july-data-processing/MSC_AI_%26_DATA_SCIENCE_ASSIGNMENT_JULY_2025_AMOS_OKPE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# MSC AI & DATA SCIENCE ASSIGNMENT\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> **Module**: MSc ‚Äì Introduction to Programming for AI and Data Science  \n",
        "**Assignment Title**: Data Pre-processing  \n",
        "**Student Name**: Amos Orevaoghene Okpe  \n",
        "**Date**: July 2025\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://res.cloudinary.com/dhqdentd8/image/upload/v1751731557/intro_image_gqdvqj.jpg\" width=\"90%\" alt=\"Data Science Icon\"/>\n",
        "</p>\n",
        "\n",
        "## üìò Introduction\n",
        "\n",
        "This notebook presents a complete solution to the course assignment titled **\"Customer Data Pre-processing\"** for the module *Introduction to Programming for Artificial Intelligence and Data Science*.\n",
        "\n",
        "The objective is to:\n",
        "- Process raw customer data exported from a company's system.\n",
        "- Clean, restructure, and transform the data into a nested JSON format.\n",
        "- Generate filtered subsets and calculate custom metrics.\n",
        "- Visualize key patterns using **Pandas** and **Seaborn**.\n",
        "\n",
        "All tasks are performed using **Python‚Äôs standard libraries**, and the output files and visualizations are saved as required by the submission guidelines.\n"
      ],
      "metadata": {
        "id": "qdI-41FxuGP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÇ About the Dataset\n",
        "\n",
        "The dataset `acw_user_data.csv` contains customer records exported from a legacy company system. Each row represents a customer and includes a range of attributes such as:\n",
        "\n",
        "- **Personal Information**: First name, surname, marital status, dependants, etc.\n",
        "- **Vehicle Details**: Make, model, year, and type of vehicle.\n",
        "- **Credit Card Info**: Card number, start and end date, IBAN, and security code.\n",
        "- **Address Details**: Main address, city, and postcode.\n",
        "- **Employment & Commute**: Employer name, salary, and commute distance.\n",
        "\n",
        "The dataset is structured as a **flat CSV file**, which is not suitable for direct analysis. A major part of this coursework is to **transform this flat structure into a nested JSON representation**, clean potential data issues, and\n",
        "derive useful additional metrics.\n",
        "\n",
        "### üìå Source of Data\n",
        "This is a **synthetic dataset** provided as part of the MSc module *\"Introduction to Programming for Artificial Intelligence and Data Science\"*. It was designed for academic purposes and simulates real-world customer data, including potential formatting inconsistencies and relationships across fields.\n",
        "<br>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "GHdAW3MzRBV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Statements\n"
      ],
      "metadata": {
        "id": "cCHuoY72XpC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "E_91wYTUq1jy"
      },
      "outputs": [],
      "source": [
        "# Importing standard Python libraries for data processing and file handling\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> üìÅ **Working from Google Drive**\n",
        "\n",
        "If you're running this notebook on **Google Colab**, you'll need to **mount your Google Drive** to access the dataset (`acw_user_data.csv`).\n",
        "\n",
        "If you're **not using Google Drive**, feel free to **skip or comment out** the next cell."
      ],
      "metadata": {
        "id": "ZDXg8B_oblce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (only needed if you're running from Google Colab and using Drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ8BeWiTRJtP",
        "outputId": "a2c60f4f-b214-4fb5-fee8-8e25a3e694f9"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "H0UNlHrCeCz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset\n",
        "\n",
        "The first task involves loading the flat CSV file `acw_user_data.csv` using the built-in `csv` module. This will allow us to parse the file into a list of dictionaries for easier processing in subsequent tasks.\n",
        "\n",
        "The data will be previewed to confirm correct parsing.\n",
        "\n",
        " - Replace the line below with the correct file path\n",
        "```\n",
        "file_path = '/content/drive/MyDrive/University of Hull/Assignment-Data-Processing/acw_user_data.csv'\n",
        "```\n"
      ],
      "metadata": {
        "id": "Y2KCos-eeiiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the line below with the correct file path..\n",
        "file_path = '/content/drive/MyDrive/University of Hull/Assignment-Data-Processing/acw_user_data.csv'"
      ],
      "metadata": {
        "id": "keYaUfxte9Ds"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1 ‚Äì Read the provided ACW Data using the csv library"
      ],
      "metadata": {
        "id": "DqbIhvUxmMQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []  # this will hold all records\n",
        "\n",
        "# Open the CSV file\n",
        "with open(file_path, mode='r') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    headers = reader.fieldnames\n",
        "    for row in reader:\n",
        "        data.append(row)"
      ],
      "metadata": {
        "id": "XX2RviEhcuhs"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the headers, first and last row of out data."
      ],
      "metadata": {
        "id": "gaTr1KuvxdGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preview our data, to get some insight\n",
        "print(f\"Number of rows (records): {len(data)}\")\n",
        "print(f\"Number of columns: {len(headers)}\")\n",
        "print(f\"Column headers:\")\n",
        "\n",
        "for i, header in enumerate(headers, start=1):\n",
        "    print(f\"{i:2}. {header}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AGkstcznj0l",
        "outputId": "10738b1d-5ac3-4dbf-d119-655a31e9a79e"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows (records): 1000\n",
            "Number of columns: 23\n",
            "Column headers:\n",
            " 1. Address Street\n",
            " 2. Address City\n",
            " 3. Address Postcode\n",
            " 4. Age (Years)\n",
            " 5. Distance Commuted to Work (Km)\n",
            " 6. Employer Company\n",
            " 7. Credit Card Start Date\n",
            " 8. Credit Card Expiry Date\n",
            " 9. Credit Card Number\n",
            "10. Credit Card CVV\n",
            "11. Dependants\n",
            "12. First Name\n",
            "13. Bank IBAN\n",
            "14. Last Name\n",
            "15. Marital Status\n",
            "16. Yearly Pension (Dollar)\n",
            "17. Retired\n",
            "18. Yearly Salary (Dollar)\n",
            "19. Sex\n",
            "20. Vehicle Make\n",
            "21. Vehicle Model\n",
            "22. Vehicle Year\n",
            "23. Vehicle Type\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First row: {data[0]}\")\n",
        "print(f\"Last row: {data[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDyGZDnEzgec",
        "outputId": "c76c3703-7257-4520-8bd9-dab9bf30eadf"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: {'Address Street': '70 Lydia isle', 'Address City': 'Lake Conor', 'Address Postcode': 'S71 7XZ', 'Age (Years)': '89', 'Distance Commuted to Work (Km)': '0', 'Employer Company': 'N/A', 'Credit Card Start Date': '08/18', 'Credit Card Expiry Date': '11/27', 'Credit Card Number': '676373692463', 'Credit Card CVV': '875', 'Dependants': '3', 'First Name': 'Kieran', 'Bank IBAN': 'GB62PQKB71416034141571', 'Last Name': 'Wilson', 'Marital Status': 'married or civil partner', 'Yearly Pension (Dollar)': '7257', 'Retired': 'True', 'Yearly Salary (Dollar)': '72838', 'Sex': 'Male', 'Vehicle Make': 'Hyundai', 'Vehicle Model': 'Bonneville', 'Vehicle Year': '2009', 'Vehicle Type': 'Pickup'}\n",
            "Last row: {'Address Street': 'Flat 9 Mohamed route', 'Address City': 'West Glen', 'Address Postcode': 'LL3M 4WS', 'Age (Years)': '80', 'Distance Commuted to Work (Km)': '0', 'Employer Company': 'N/A', 'Credit Card Start Date': '12/14', 'Credit Card Expiry Date': '01/16', 'Credit Card Number': '180020306382110', 'Credit Card CVV': '903', 'Dependants': '1', 'First Name': 'Sheila', 'Bank IBAN': 'GB45ORXV49380519147072', 'Last Name': 'Russell', 'Marital Status': 'single', 'Yearly Pension (Dollar)': '22869', 'Retired': 'True', 'Yearly Salary (Dollar)': '25788', 'Sex': 'Female', 'Vehicle Make': 'Geo', 'Vehicle Model': 'S7', 'Vehicle Year': '1993', 'Vehicle Type': 'Van/Minivan'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets Check our first row and also check the data types\n",
        "print(\"\\nFirst row:\")\n",
        "for header, value in data[0].items():\n",
        "    print(f\"{header}: {value} - {type(value)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAqKOMLLyfzj",
        "outputId": "d377bbc7-7c3f-4a2d-afb3-17d34baac020"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First row:\n",
            "Address Street: 70 Lydia isle - <class 'str'>\n",
            "Address City: Lake Conor - <class 'str'>\n",
            "Address Postcode: S71 7XZ - <class 'str'>\n",
            "Age (Years): 89 - <class 'str'>\n",
            "Distance Commuted to Work (Km): 0 - <class 'str'>\n",
            "Employer Company: N/A - <class 'str'>\n",
            "Credit Card Start Date: 08/18 - <class 'str'>\n",
            "Credit Card Expiry Date: 11/27 - <class 'str'>\n",
            "Credit Card Number: 676373692463 - <class 'str'>\n",
            "Credit Card CVV: 875 - <class 'str'>\n",
            "Dependants: 3 - <class 'str'>\n",
            "First Name: Kieran - <class 'str'>\n",
            "Bank IBAN: GB62PQKB71416034141571 - <class 'str'>\n",
            "Last Name: Wilson - <class 'str'>\n",
            "Marital Status: married or civil partner - <class 'str'>\n",
            "Yearly Pension (Dollar): 7257 - <class 'str'>\n",
            "Retired: True - <class 'str'>\n",
            "Yearly Salary (Dollar): 72838 - <class 'str'>\n",
            "Sex: Male - <class 'str'>\n",
            "Vehicle Make: Hyundai - <class 'str'>\n",
            "Vehicle Model: Bonneville - <class 'str'>\n",
            "Vehicle Year: 2009 - <class 'str'>\n",
            "Vehicle Type: Pickup - <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùå From the above output we can see that the data types are all string, hence we will need to do some data casting to convert relevant fields like age, yearly salary, ect to float or integer, for easy manipulation and calculation later."
      ],
      "metadata": {
        "id": "L0JUrhfn1NVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 ‚Äì Convert Flat CSV Records into Nested Structures\n",
        "\n",
        "The raw data read from the CSV file is completely flat, meaning each customer's attributes are stored as separate keys. To better represent the data and prepare it for JSON export, we will group related fields into **nested dictionaries**, including:\n",
        "\n",
        "- üì¶ **Vehicle** ‚Üí `make`, `model`, `year`, `type`\n",
        "- üí≥ **Credit Card** ‚Üí `start_date`, `end_date`, `number`, `security_code`, `iban`\n",
        "- üè† **Address** ‚Üí `address`, `city`, `postcode`\n",
        "\n",
        "All other fields remain at the top level. Data types will also be cast appropriately (e.g., integers for year, floats for salary).\n"
      ],
      "metadata": {
        "id": "AYVXX5NqmD-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform flat records into nested dictionaries using correct keys from the result above\n",
        "# Convert from str to correct data types\n",
        "\n",
        "def transform_record(row: dict):\n",
        "    \"\"\"\n",
        "    Converts flat records to nested dictionaries.\n",
        "    Returns a dictionary or None if any error occurs during conversion.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert numeric fields with appropriate types\n",
        "        row['Vehicle Year'] = int(row.get('Vehicle Year', 0))\n",
        "        row['Yearly Salary (Dollar)'] = float(row.get('Yearly Salary (Dollar)', 0))\n",
        "        row['Distance Commuted to Work (Km)'] = float(row.get('Distance Commuted to Work (Km)', 0))\n",
        "        row['Age (Years)'] = int(row.get('Age (Years)', 0))\n",
        "        row['Yearly Pension (Dollar)'] = float(row.get('Yearly Pension (Dollar)', 0))\n",
        "\n",
        "        # Convert Employer Company to None if N/A\n",
        "        row['Employer Company'] = row.get(\"Employer Company\").strip() if row.get(\"Employer Company\") and row.get(\"Employer Company\").strip().upper() != \"N/A\" else None\n",
        "\n",
        "        # Build nested structure\n",
        "        record = {\n",
        "            \"first_name\": row.get(\"First Name\"),\n",
        "            \"last_name\": row.get(\"Last Name\"),\n",
        "            \"sex\": row.get(\"Sex\"),\n",
        "            \"age\": row['Age (Years)'],\n",
        "            \"marital_status\": row.get(\"Marital Status\"),\n",
        "            \"dependants\": row['Dependants'],\n",
        "            \"employer\": row.get(\"Employer Company\"),\n",
        "            \"retired\": row.get(\"Retired\") == \"True\",  # convert to actual boolean\n",
        "            \"salary\": row['Yearly Salary (Dollar)'],\n",
        "            \"pension\": row['Yearly Pension (Dollar)'],\n",
        "            \"commute_distance\": row['Distance Commuted to Work (Km)'],\n",
        "\n",
        "            \"vehicle\": {\n",
        "                \"make\": row.get(\"Vehicle Make\"),\n",
        "                \"model\": row.get(\"Vehicle Model\"),\n",
        "                \"year\": row['Vehicle Year'],\n",
        "                \"type\": row.get(\"Vehicle Type\")\n",
        "            },\n",
        "            \"credit_card\": {\n",
        "                \"start_date\": row.get(\"Credit Card Start Date\"),\n",
        "                \"end_date\": row.get(\"Credit Card Expiry Date\"),\n",
        "                \"number\": row.get(\"Credit Card Number\"),\n",
        "                \"security_code\": row.get(\"Credit Card CVV\"),\n",
        "                \"iban\": row.get(\"Bank IBAN\")\n",
        "            },\n",
        "            \"address\": {\n",
        "                \"address\": row.get(\"Address Street\"),\n",
        "                \"city\": row.get(\"Address City\"),\n",
        "                \"postcode\": row.get(\"Address Postcode\")\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return record\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error transforming row: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Oszu1DCb4LMi"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Cleaning the 'Dependants' Column\n",
        "\n",
        "The `dependants` field contains some missing or empty values (`\"\"`, `\" \"`), which may cause issues during type conversion. These values are replaced with a meaningful default value (`0`). A list of the row numbers where such corrections occur is printed as required.\n"
      ],
      "metadata": {
        "id": "9zlr4q4QPG-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix dependants column and log rows with the issue\n",
        "fixed_dependants = []\n",
        "\n",
        "for index, row in enumerate(data):\n",
        "    val = row.get(\"Dependants\", 0)\n",
        "    if val == \"\":\n",
        "        row['Dependants'] = 0\n",
        "        fixed_dependants.append(index)\n",
        "    else:\n",
        "        row['Dependants'] = int(row.get('Dependants', 0)) if row.get('Dependants') else 0\n",
        "\n",
        "print(f\"‚úÖ Fixed rows for dependants: {fixed_dependants}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4OGaRQDPXvW",
        "outputId": "e820e8bc-71c2-4f1e-f531-d1632ae8f6ef"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fixed rows for dependants: [21, 109, 179, 205, 270, 272, 274, 358, 460, 468, 579, 636, 679, 725, 822, 865, 917, 931, 983]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the transformation to all records\n",
        "transformed_data = [transform_record(row) for row in data if transform_record(row)]\n",
        "\n",
        "# Preview result\n",
        "print(\"Example Transformed Record:\")\n",
        "print(json.dumps(transformed_data[0], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCpq1RQS6FXI",
        "outputId": "c5b09237-06b4-4600-8efb-2ae9b22a852b"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Transformed Record:\n",
            "{\n",
            "  \"first_name\": \"Kieran\",\n",
            "  \"last_name\": \"Wilson\",\n",
            "  \"sex\": \"Male\",\n",
            "  \"age\": 89,\n",
            "  \"marital_status\": \"married or civil partner\",\n",
            "  \"dependants\": 3,\n",
            "  \"employer\": null,\n",
            "  \"retired\": true,\n",
            "  \"salary\": 72838.0,\n",
            "  \"pension\": 7257.0,\n",
            "  \"commute_distance\": 0.0,\n",
            "  \"vehicle\": {\n",
            "    \"make\": \"Hyundai\",\n",
            "    \"model\": \"Bonneville\",\n",
            "    \"year\": 2009,\n",
            "    \"type\": \"Pickup\"\n",
            "  },\n",
            "  \"credit_card\": {\n",
            "    \"start_date\": \"08/18\",\n",
            "    \"end_date\": \"11/27\",\n",
            "    \"number\": \"676373692463\",\n",
            "    \"security_code\": \"875\",\n",
            "    \"iban\": \"GB62PQKB71416034141571\"\n",
            "  },\n",
            "  \"address\": {\n",
            "    \"address\": \"70 Lydia isle\",\n",
            "    \"city\": \"Lake Conor\",\n",
            "    \"postcode\": \"S71 7XZ\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíæ Task 4 ‚Äì Save All Transformed Records to processed.json\n",
        "\n",
        "After successfully transforming the flat CSV records into a nested dictionary structure, I am now saving the full dataset to a file named `processed.json`.\n",
        "\n",
        "This file contains a list of dictionaries where each dictionary represents a single customer. The format follows the JSON structure outlined in the appendix of the assignment brief, including nested fields for `vehicle`, `credit_card`, and `address`.\n",
        "\n",
        "The output is saved using the built-in `json` module with indentation for better readability.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SjE2SAdnWoLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving my transformed dataset to processed.json\n",
        "\n",
        "output_file = \"processed.json\"\n",
        "\n",
        "try:\n",
        "    with open(output_file, mode=\"w\") as f:\n",
        "        json.dump(transformed_data, f, indent=2)\n",
        "    print(f\"‚úÖ Successfully wrote {len(transformed_data)} records to {output_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to write to {output_file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmGOvMUFXRhU",
        "outputId": "3610d15e-4b72-49c6-fc41-f843436ee84c"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully wrote 1000 records to processed.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5 ‚Äì Saving Retired and Employed Customers\n",
        "Now that I have a clean list of transformed records (`transformed_data`), I want to separate customers into two groups:\n",
        "\n",
        "To keep my notebook organized and reusable, I decided to wrap the filtering logic into a class called `CustomerFilter`.\n",
        "\n",
        "This class makes it easier to:\n",
        "- Filter customer records based on conditions\n",
        "- Save filtered results to specific JSON files\n",
        "- Extend the logic for other filtering tasks later when needed\n",
        "\n",
        "> The class includes methods for handling retired and employed customers.\n"
      ],
      "metadata": {
        "id": "l5eB4n3OYsVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CustomerFilter class to organize my filtering logic\n",
        "\n",
        "class CustomerFilter:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def is_retired(self, redord):\n",
        "        \"\"\"Checks if a customer is retired.\n",
        "        Returns True if the customer is retired, False otherwise.\n",
        "        \"\"\"\n",
        "        return bool(redord.get(\"retired\"))\n",
        "\n",
        "    def is_employed(self, redord):\n",
        "        \"\"\"Checks if a customer is employed.\n",
        "        Returns True if the customer is employed, False otherwise.\n",
        "        \"\"\"\n",
        "        employer = redord.get(\"employer\")\n",
        "        return employer and employer != 0\n",
        "\n",
        "    def save_filtered_records(self, condition_function, filename):\n",
        "        \"\"\"\n",
        "        Filters self.data using condition_function and saves to a JSON file.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            filtered = [record for record in self.data if condition_function(record)]\n",
        "            with open(filename, \"w\") as f:\n",
        "                json.dump(filtered, f, indent=2)\n",
        "            print(f\"‚úÖ I saved {len(filtered)} records to {filename}\")\n",
        "            # to show numbers of retired customers from total\n",
        "            print(f\"This shows that out of {len(data)} customers - {len(filtered)} are {(condition_function.__name__).split('_')[1]}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "4EK-DlMKec5c"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the class to save the required files\n",
        "# Create filter instance\n",
        "filterer = CustomerFilter(transformed_data)"
      ],
      "metadata": {
        "id": "6Du5Pit8gwDA"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save retired customers\n",
        "filterer.save_filtered_records(filterer.is_retired, \"retired.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBdk1jnGglyB",
        "outputId": "23d3da4c-4ee0-42aa-8c82-41f70384776b"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ I saved 246 records to retired.json\n",
            "This shows that out of 1000 customers - 246 are retired.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save retired customers\n",
        "filterer.save_filtered_records(filterer.is_employed, \"employed.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvj0IJIfg1nQ",
        "outputId": "379849fa-6fcf-4caa-8ed6-50f7964f6567"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ I saved 754 records to employed.json\n",
            "This shows that out of 1000 customers - 754 are employed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 6 ‚Äì Flagging Credit Card Issues (Over 10-Year Gaps)\n",
        "\n",
        "The client mentioned there may be data quality issues with some credit card entries ‚Äî specifically where the time span between the **start date** and **expiry date** exceeds **10 years**.\n",
        "\n",
        "The dates are in credit card format (`MM/YY`), so I wrote a function that accepts a single row from the raw CSV data, parses both dates, and checks if the difference is more than 10 years.\n",
        "\n",
        "> Any customer flagged by this function will be saved to `remove_ccard.json`.\n"
      ],
      "metadata": {
        "id": "bXOrg_WZmp-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def has_invalid_cc_date(row):\n",
        "    \"\"\"\n",
        "    Accepts a raw CSV row and returns True if the credit card\n",
        "    duration exceeds 10 years (based on MM/YY format).\n",
        "    \"\"\"\n",
        "    start = row.get(\"Credit Card Start Date\", \"\")\n",
        "    end = row.get(\"Credit Card Expiry Date\", \"\")\n",
        "\n",
        "    try:\n",
        "        start_dt = datetime.strptime(start, \"%m/%y\")\n",
        "        end_dt = datetime.strptime(end, \"%m/%y\")\n",
        "        duration_years = (end_dt.year - start_dt.year) + ((end_dt.month - start_dt.month) / 12)\n",
        "        return duration_years > 10\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Skipping row due to date parsing error: {e}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "JxDcoFKvnPZp"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and transform only the rows with invalid credit card durations\n",
        "flagged_cc_customers = [transform_record(row) for row in data if has_invalid_cc_date(row) and transform_record(row)]"
      ],
      "metadata": {
        "id": "cNw-YAOQnW4D"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to remove_ccard.json\n",
        "try:\n",
        "    with open(\"remove_ccard.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(flagged_cc_customers, f, indent=2)\n",
        "    print(f\"‚úÖ I saved {len(flagged_cc_customers)} flagged records to remove_ccard.json\")\n",
        "    print(f\"This shows that out of {len(data)} customers - {len(flagged_cc_customers)} are having credit card issues.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to write remove_ccard.json: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2ePTS7VnnXe",
        "outputId": "d38733e4-df7d-40c5-9b9b-0dd57347427f"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ I saved 252 flagged records to remove_ccard.json\n",
            "This shows that out of 1000 customers - 252 are having credit card issues.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 7 ‚Äì Salary per Commute Distance (Salary-Commute Metric)\n",
        "\n",
        "To support customer ranking based on financial efficiency, I‚Äôve added a new metric called `Salary-Commute`. This measures how much a customer earns per kilometre of their commute.\n",
        "\n",
        "Here's how I calculated it:\n",
        "- If a customer commutes **more than 1 km**, I divide their salary by the commute distance.\n",
        "- If they commute **1 km or less**, I simply assign their full salary as the `Salary-Commute` value.\n",
        "\n",
        "> After calculating this for all customers, I sorted the list in ascending order and saved it to `commute.json`.\n"
      ],
      "metadata": {
        "id": "2xSFPAucofv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Step 1: Load from processed.json\n",
        "try:\n",
        "    with open(\"processed.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        processed_records = json.load(f)\n",
        "except Exception as e:\n",
        "    print(f\"Couldn't read processed.json: {e}\")\n",
        "    processed_records = []"
      ],
      "metadata": {
        "id": "vrvjPzPQovi7"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Add salary-commute metric\n",
        "for person in processed_records:\n",
        "    salary = person.get(\"salary\", 0)\n",
        "    commute = person.get(\"commute_distance\", 0)\n",
        "\n",
        "    try:\n",
        "        salary = float(salary)\n",
        "        commute = float(commute)\n",
        "\n",
        "        if commute > 1:\n",
        "            person[\"Salary-Commute\"] = round(salary / commute, 2)\n",
        "        else:\n",
        "            person[\"Salary-Commute\"] = round(salary, 2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error calculating salary_commute for person: {e}\")\n",
        "        person[\"Salary-Commute\"] = salary  # fallback to just salary"
      ],
      "metadata": {
        "id": "rJEPCsN4o2Za"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Sort records in ascending order\n",
        "sorted_records = sorted(processed_records, key=lambda x: x.get(\"Salary-Commute\", float(\"inf\")))\n"
      ],
      "metadata": {
        "id": "5Bo_wASro8i0"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Save to commute.json\n",
        "try:\n",
        "    with open(\"commute.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(sorted_records, f, indent=2)\n",
        "    print(f\"‚úÖ I saved {len(sorted_records)} sorted records to commute.json\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to save commute.json: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CnaqH4ko_I-",
        "outputId": "e6c544a2-d0f0-4b24-ca01-c1d6bc4eb7fb"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ I saved 1000 sorted records to commute.json\n"
          ]
        }
      ]
    }
  ]
}